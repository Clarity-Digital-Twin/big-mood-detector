Tasks to Enable Dual-Model Pipeline

1. Implement Circadian Feature Extraction for XGBoost (Impact: High, Effort=M)
	•	Problem: The XGBoost mood model expects a 36-dimensional feature vector per day derived from sleep/circadian patterns ￼. Currently these indices (e.g. sleep regularity, phase shifts, L5/M10 activity levels) are not computed in the Python pipeline (previously generated via a MATLAB script) ￼. This gap means we cannot feed Apple Health data into the XGBoost model yet.
	•	Implementation Outline: Extend the feature processing code to calculate the full set of circadian and sleep features in Python. Using the daily sleep summary (from SleepAggregator) and activity summary, implement calculations for metrics like Sleep Regularity Index, Interdaily Stability, Intradaily Variability, relative amplitude, L5/M10 values, sleep onset/wake variability, etc., mirroring the research features ￼. Incorporate any needed time-series analysis (e.g. use tsfresh on hourly activity if available) to approximate the original indices. Populate the AdvancedFeatures data class and its to_ml_features() to produce the 36-length numpy array expected by the XGBoost model ￼. Finally, load the pre-trained XGBoost model .pkl files and integrate a prediction function that takes these feature vectors and outputs daily risk scores (for depression, mania, etc.) ￼. Key files to modify will include advanced_feature_engineering.py (to fill in any stub computations) and potentially a loader in the model directory for the XGBoost pickles.
	•	Tests / Acceptance Criteria: Create unit tests for the feature calculations using known patterns (e.g., a synthetic week of idealized sleep times) to ensure each feature (duration, efficiency, variability measures) returns plausible values. Integration test by running FeatureExtractionService.extract_advanced_features on sample HealthKit data and verifying it returns a feature vector of length 36 for each day, with no nulls. Confirm that feeding this vector into the loaded XGBoost model yields a prediction without errors. As a benchmark, if there is reference output (e.g. from the MATLAB script or literature), compare a few feature values or risk scores to ensure the Python implementation is in range.
	•	Risks / Mitigations: Risk 1: The Python-computed features might not exactly match the original MATLAB features, potentially impacting model accuracy ￼. Mitigation: Start with the most impactful features (total sleep, efficiency, sleep timing) which are straightforward, and gradually refine the complex ones, verifying against expected trends (e.g., increasing fragmentation index when sleep is split into multiple episodes). Risk 2: Incomplete data (e.g., a day missing heart rate or activity) could lead to missing feature values or incorrect normalization. Mitigation: Define defaults or carry forward averages for missing metrics and ensure the feature extraction code can handle empty inputs gracefully (e.g., if no activity data for a day, set activity-related features to 0) so that the XGBoost still produces a result ￼. Overall, this task unlocks the core predictive pipeline by generating required inputs for the proven XGBoost models.

2. Build Raw Sequence Pipeline for PAT Model (Impact: High, Effort=L)
	•	Problem: The Pretrained Actigraphy Transformer (PAT) requires raw high-resolution activity data (e.g. minute-level accelerometer readings over ~1 week) as input ￼. Our current pipeline only produces daily aggregates (total steps, etc.) and lacks a sequence tensor for PAT. Without a way to extract and format the Apple HealthKit data into a continuous time-series, we cannot leverage PAT’s sequence model on the same data ￼.
	•	Implementation Outline: Develop a data pipeline to retrieve and prepare minute-by-minute activity readings for PAT. Using the Apple Health XML parser (from ActivityParser in infrastructure/parsers/xml), extract time-stamped activity events such as step counts or active energy expenditures ￼. Aggregate these into a uniform time series at 1-minute resolution – for example, for each day or week, create an array of 10,080 minutes (7 days × 24h × 60m) where each entry is the step count (or a proxy for movement intensity) for that minute ￼. Fill in gaps with zeros if no activity is recorded in a given minute. Once the sequence assembly is in place, integrate the PAT model: load the pre-trained PAT weights (e.g. PAT-M_29k_weights.h5) into a corresponding model architecture (likely a Keras/TensorFlow transformer model). Implement an inference method that takes the 1-week activity sequence and runs a forward pass through PAT. Since we have no fine-tuned classifier yet, this could output either the learned embedding (latent features) or an anomaly score. This step may involve adding a small wrapper head to PAT if we want a predictive score, or simply using PAT’s internal representation as an output for now ￼. Key files: possibly create a new module (e.g. pat_pipeline.py) to hold sequence construction and model loading logic, leveraging reference_repos/Pretrained-Actigraphy-Transformer for model structure definition.
	•	Tests / Acceptance Criteria: Verify the sequence extraction with a unit test: feed a small set of known activity records (e.g., 30 minutes of 100 steps each, spread over an hour) and ensure the resulting minute-level array correctly places those steps in the right indices with zeros elsewhere. Test the sequence length for a larger sample (e.g., 1-day data yields 1440 points, 7-days yields 10080 points). For the model, perform a “smoke test” by loading PAT weights and running a dummy sequence through it – confirm that the output tensor has the expected shape (for example, an embedding of a certain dimension, or class probabilities if a head is attached). Because the real PAT model is large, use the smaller variant or a shortened sequence for testing to keep runtime reasonable ￼. It’s acceptable initially to just ensure no exceptions and that outputs exist. Also include an integration test where the pipeline takes real Apple Health XML data (if available in tests) to produce a PAT input array and processes it, asserting that the pipeline completes successfully and returns an output object.
	•	Risks / Mitigations: Risk 1: Model integration complexity – reconstructing the PAT architecture to load weights can be error-prone and time-consuming. The transformer expects a specific patching of the 10080-length sequence (patch size 18, yielding 560 tokens) ￼; any mismatch in architecture (e.g., embedding dimensions or layer counts) will cause loading failures. Mitigation: Start with the provided PAT example code/notebooks to implement the model class exactly as pretrained, and verify layer-by-layer shapes. Use PAT’s smaller model for initial trials to reduce complexity, and only then scale up (the repo suggests PAT-M as a good balance) ￼. Risk 2: Performance and optionality – running a full week through a transformer is computationally heavy, possibly too slow for real-time use. In early stages, PAT is meant as a parallel, optional analysis ￼. Mitigation: Make PAT processing asynchronous or offline: for example, compute PAT outputs in a background thread or cache results so it doesn’t block the main prediction flow. Also, keep the PAT integration modular – if PAT data is unavailable or the computation is toggled off, the system should still function (only XGBoost features) without errors. By addressing these risks, we set up the PAT pipeline to run alongside XGBoost when needed, enabling future ensemble improvements.

3. Parallel Inference & Ensemble Integration (Impact: Medium, Effort=M)
	•	Problem: With both the XGBoost and PAT pipelines in place, we need to run them in parallel on the same user data and combine their outputs. Currently, there is no coordination layer to ensure that for a given user-day, we produce both an XGBoost risk prediction and a PAT-derived insight. Without an integration step, we can’t realize the benefits of an ensemble model that merges these two signals ￼.
	•	Implementation Outline: Create a higher-level service or workflow (e.g. a DualModelPredictor class or an orchestrator function) that coordinates the two pipelines. This component will take the parsed HealthKit data and first generate the daily feature vector for XGBoost and the minute-level sequence for PAT. It should then invoke the XGBoost model to get a probability (or risk score) and invoke the PAT model to get its output for the corresponding period. Once both results are obtained, the service combines them – initially, a simple approach like averaging the risk scores or outputting both scores side by side can be used ￼. For example, if XGBoost predicts a 20% mania risk for a certain day and PAT (after suitable scaling or classification) predicts 30%, the ensemble output might be a 25% risk or a tuple of both. The combination logic should be easily swappable (we might later use a learned meta-model or just use PAT’s features as additional input to XGBoost) ￼. This task will involve modifying the prediction flow (perhaps in a FastAPI endpoint or a CLI tool) to call the new dual pipeline instead of just XGBoost alone. Also, ensure the outputs are tagged with the date or period they pertain to, since PAT’s input window (e.g. a week ending on Day D) should align with Day D’s XGBoost features.
	•	Tests / Acceptance Criteria: Write an integration test that simulates end-to-end data flow: given a small set of sleep, activity, and heart rate records, run the dual-model predictor and verify that the result contains both an XGBoost score and a PAT output for the same day. If using averaging, verify the value lies between the two model outputs. Test edge cases: if PAT sequence is unavailable (e.g., user provided only JSON daily summaries, no raw data), the system should still return XGBoost results with PAT output marked as not available or skipped. Conversely, if XGBoost features are missing (e.g., no sleep data for a day), ensure the pipeline can still potentially return a PAT analysis for that period. The acceptance criteria is that both models can run on at least one common date and produce a merged result without manual intervention, demonstrating the ensemble capability.
	•	Risks / Mitigations: Risk 1: Misalignment of predictions – PAT’s analysis might cover a multi-day window whereas XGBoost is day-specific, so combining them incorrectly could mislead (e.g., PAT detecting a pattern over a week that doesn’t correspond exactly to the single-day risk). Mitigation: Clearly define the alignment: likely use the latest day of PAT’s input window as the day for which we assign PAT’s output. Document this assumption and ensure the code constructs the PAT input window accordingly (e.g., the 7 days leading up to the target date) so that both model outputs genuinely refer to the same target day. Risk 2: Unproven ensemble benefit – Simply averaging or combining outputs may not improve accuracy and could even dampen a strong signal from one model ￼. Mitigation: Treat the ensemble output as experimental initially. We will log or compare the models’ outputs: if PAT’s contributions correlate with known outcomes, we can increase its weight, or if not, we might keep XGBoost as the primary indicator (as suggested, XGBoost remains the primary engine and PAT a secondary module) ￼. By structuring the code to allow easy toggling or re-weighting of model outputs, we can iteratively find the best combination strategy. This task completes the minimal integration needed to run both models on the same data, setting the stage for evaluating the ensemble’s performance.