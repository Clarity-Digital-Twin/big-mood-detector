#!/usr/bin/env python3
"""
Comprehensive XML Pipeline End-to-End Test

Tests the complete flow:
1. XML parsing (streaming)
2. Sleep window aggregation
3. Activity sequence extraction
4. Feature engineering
5. ML predictions (XGBoost + PAT ensemble)
6. Clinical interpretation
"""

import sys
import time
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

import numpy as np

from big_mood_detector.application.ensemble_orchestrator import EnsembleOrchestrator
from big_mood_detector.domain.entities.activity_record import ActivityRecord
from big_mood_detector.domain.entities.heart_rate_record import HeartRateRecord
from big_mood_detector.domain.entities.sleep_record import SleepRecord
from big_mood_detector.domain.services.activity_sequence_extractor import (
    ActivitySequenceExtractor,
)
from big_mood_detector.domain.services.clinical_feature_extractor import (
    ClinicalFeatureExtractor,
)
from big_mood_detector.domain.services.clinical_interpreter import ClinicalInterpreter
from big_mood_detector.domain.services.sleep_window_analyzer import SleepWindowAnalyzer
from big_mood_detector.infrastructure.ml_models import PATModel, XGBoostMoodPredictor
from big_mood_detector.infrastructure.parsers.xml.streaming_adapter import (
    StreamingXMLParser,
)


def print_header(title):
    """Print formatted section header."""
    print(f"\n{'='*80}")
    print(f" {title}")
    print("=" * 80)


def test_xml_parsing():
    """Step 1: Parse XML and collect records."""
    print_header("STEP 1: XML PARSING")

    xml_path = Path("apple_export/export.xml")
    if not xml_path.exists():
        print("‚ùå XML file not found")
        return None, None, None

    print(
        f"üìÅ Processing: {xml_path.name} ({xml_path.stat().st_size / 1024**2:.1f} MB)"
    )

    parser = StreamingXMLParser()
    sleep_records = []
    activity_records = []
    hr_records = []

    start_time = time.time()
    records_count = 0

    print("üîÑ Parsing XML with streaming parser...")

    for record in parser.parse_file(xml_path):
        if isinstance(record, SleepRecord):
            sleep_records.append(record)
        elif isinstance(record, ActivityRecord):
            activity_records.append(record)
        elif isinstance(record, HeartRateRecord):
            hr_records.append(record)

        records_count += 1
        if records_count % 50000 == 0:
            elapsed = time.time() - start_time
            rate = records_count / elapsed
            print(f"   Processed {records_count:,} records ({rate:.0f} rec/s)")

    parse_time = time.time() - start_time

    print("\n‚úÖ Parsing Complete:")
    print(f"   Total records: {records_count:,}")
    print(f"   Time: {parse_time:.1f}s")
    print(f"   Rate: {records_count/parse_time:.0f} records/second")
    print("\nüìä Breakdown:")
    print(f"   Sleep: {len(sleep_records):,}")
    print(f"   Activity: {len(activity_records):,}")
    print(f"   Heart Rate: {len(hr_records):,}")

    return sleep_records, activity_records, hr_records


def test_sleep_aggregation(sleep_records):
    """Step 2: Aggregate sleep windows."""
    print_header("STEP 2: SLEEP WINDOW AGGREGATION")

    if not sleep_records:
        print("‚ùå No sleep records to process")
        return None

    analyzer = SleepWindowAnalyzer()

    print(f"üîÑ Analyzing {len(sleep_records):,} sleep records...")
    start_time = time.time()

    windows = analyzer.analyze_sleep_episodes(sleep_records)

    analysis_time = time.time() - start_time

    print("\n‚úÖ Sleep Analysis Complete:")
    print(f"   Windows created: {len(windows)}")
    print(f"   Time: {analysis_time:.2f}s")

    # Show sample windows
    if windows:
        recent = sorted(windows, key=lambda w: w.start_time)[-3:]
        print("\nüìä Recent Sleep Windows:")
        for w in recent:
            print(
                f"   {w.start_time.date()}: {w.total_duration_hours:.1f}h "
                f"({w.episode_count} episodes)"
            )

    return windows


def test_activity_extraction(activity_records):
    """Step 3: Extract activity sequences."""
    print_header("STEP 3: ACTIVITY SEQUENCE EXTRACTION")

    if not activity_records:
        print("‚ùå No activity records to process")
        return None

    extractor = ActivitySequenceExtractor()

    # Get recent dates with activity
    dates = sorted({r.start_date.date() for r in activity_records})[-30:]

    print(f"üîÑ Extracting sequences for {len(dates)} recent days...")
    start_time = time.time()

    sequences = {}
    for date in dates:
        day_records = [r for r in activity_records if r.start_date.date() == date]
        if day_records:
            seq = extractor.extract_daily_sequence(day_records, date)
            sequences[date] = seq

    extract_time = time.time() - start_time

    print("\n‚úÖ Activity Extraction Complete:")
    print(f"   Days processed: {len(sequences)}")
    print(f"   Time: {extract_time:.2f}s")

    # Show sample
    if sequences:
        sample_date = list(sequences.keys())[-1]
        sample_seq = sequences[sample_date]
        total_steps = sum(sample_seq.activity_values)
        print(f"\nüìä Sample Day ({sample_date}):")
        print(f"   Total steps: {total_steps:,}")
        print(f"   Data points: {len(sample_seq.activity_values)}")

    return sequences


def test_feature_engineering(sleep_windows, activity_sequences):
    """Step 4: Extract clinical features."""
    print_header("STEP 4: FEATURE ENGINEERING")

    extractor = ClinicalFeatureExtractor()

    # Use a recent date that has both sleep and activity data
    test_dates = sorted(set(activity_sequences.keys()))[-7:]

    print(f"üîÑ Extracting features for {len(test_dates)} days...")
    start_time = time.time()

    all_features = []

    for date in test_dates:
        # Get sleep windows for this date
        date_windows = [
            w for w in sleep_windows if w.start_time.date() <= date <= w.end_time.date()
        ]

        if date_windows and date in activity_sequences:
            features = extractor.extract_clinical_features(
                sleep_windows=date_windows,
                activity_sequences={date: activity_sequences[date]},
                target_date=date,
            )

            if features:
                all_features.append(features)
                print(f"   ‚úì {date}: Extracted {len(features)} features")

    extract_time = time.time() - start_time

    print("\n‚úÖ Feature Engineering Complete:")
    print(f"   Days with features: {len(all_features)}")
    print(f"   Time: {extract_time:.2f}s")

    if all_features:
        # Convert to numpy array for ML
        feature_array = np.array(all_features[0])
        print(f"   Feature vector shape: {feature_array.shape}")
        print(f"   Non-zero features: {np.count_nonzero(feature_array)}/36")

    return all_features


def test_ml_predictions(features):
    """Step 5: Run ensemble ML predictions."""
    print_header("STEP 5: ML PREDICTIONS (ENSEMBLE)")

    if not features:
        print("‚ùå No features to predict on")
        return None

    # Load models
    print("üîÑ Loading ML models...")
    start_time = time.time()

    # XGBoost
    xgboost = XGBoostMoodPredictor()
    xgboost_path = Path("model_weights/xgboost/pretrained")
    xgboost.load_models(xgboost_path)
    print("   ‚úì XGBoost loaded")

    # PAT
    pat = PATModel(model_size="medium")
    pat_weights = Path("model_weights/pat/pretrained/PAT-M_29k_weights.h5")
    if pat.load_pretrained_weights(pat_weights):
        print("   ‚úì PAT loaded")
    else:
        print("   ‚ö†Ô∏è  PAT failed to load")
        pat = None

    load_time = time.time() - start_time
    print(f"   Loading time: {load_time:.2f}s")

    # Create ensemble
    orchestrator = EnsembleOrchestrator(xgboost, pat)

    # Make predictions
    print("\nüîÑ Running ensemble predictions...")
    pred_start = time.time()

    predictions = []
    for i, feature_vector in enumerate(features[:3]):  # Test first 3 days
        result = orchestrator.predict(
            statistical_features=np.array(feature_vector, dtype=np.float32),
            activity_records=None,  # Would pass real records for PAT
        )
        predictions.append(result)

        print(f"\n   Day {i+1} Results:")
        print(f"     Depression: {result.ensemble_prediction.depression_risk:.1%}")
        print(f"     Hypomanic: {result.ensemble_prediction.hypomanic_risk:.1%}")
        print(f"     Manic: {result.ensemble_prediction.manic_risk:.1%}")
        print(f"     Confidence: {result.ensemble_prediction.confidence:.1%}")
        print(f"     Models used: {', '.join(result.models_used)}")

    pred_time = time.time() - pred_start
    print("\n‚úÖ Predictions Complete:")
    print(f"   Time: {pred_time:.3f}s")
    print(f"   Avg per prediction: {pred_time/len(predictions)*1000:.1f}ms")

    return predictions


def test_clinical_interpretation(predictions):
    """Step 6: Clinical interpretation of predictions."""
    print_header("STEP 6: CLINICAL INTERPRETATION")

    if not predictions:
        print("‚ùå No predictions to interpret")
        return

    interpreter = ClinicalInterpreter()

    print("üîÑ Generating clinical interpretations...")

    for i, pred in enumerate(predictions):
        ensemble = pred.ensemble_prediction

        # Simulate PHQ/ASRM scores based on predictions
        if ensemble.depression_risk > 0.5:
            phq_score = int(15 + ensemble.depression_risk * 10)
        else:
            phq_score = int(ensemble.depression_risk * 10)

        if ensemble.hypomanic_risk > 0.3 or ensemble.manic_risk > 0.3:
            asrm_score = int(6 + max(ensemble.hypomanic_risk, ensemble.manic_risk) * 10)
        else:
            asrm_score = int(max(ensemble.hypomanic_risk, ensemble.manic_risk) * 5)

        print(f"\nüìä Clinical Interpretation {i+1}:")
        print(
            f"   ML Predictions: Depression {ensemble.depression_risk:.1%}, "
            f"Hypomania {ensemble.hypomanic_risk:.1%}, "
            f"Mania {ensemble.manic_risk:.1%}"
        )

        # Interpret depression
        if phq_score > 4:
            dep_result = interpreter.interpret_depression_score(
                phq_score=phq_score,
                sleep_hours=7.5,  # Would come from features
                activity_steps=8000,
            )
            print("\n   Depression Assessment:")
            print(f"     Risk Level: {dep_result.risk_level.value}")
            print(f"     Clinical Summary: {dep_result.clinical_summary}")
            print(
                f"     Top Recommendation: {dep_result.recommendations[0].medication}"
            )

        # Interpret mania
        if asrm_score > 5:
            mania_result = interpreter.interpret_mania_score(
                asrm_score=asrm_score, sleep_hours=5.0, activity_steps=15000
            )
            print("\n   Mania Assessment:")
            print(f"     Risk Level: {mania_result.risk_level.value}")
            print(f"     Episode Type: {mania_result.episode_type}")
            print(f"     Clinical Summary: {mania_result.clinical_summary}")


def run_complete_test():
    """Run the complete end-to-end test."""
    print("=" * 80)
    print(" XML PIPELINE END-TO-END TEST")
    print(" Testing: Parse ‚Üí Aggregate ‚Üí Extract ‚Üí Engineer ‚Üí Predict ‚Üí Interpret")
    print("=" * 80)

    overall_start = time.time()

    # Step 1: Parse XML
    sleep_records, activity_records, hr_records = test_xml_parsing()
    if not any([sleep_records, activity_records]):
        print("\n‚ùå No data parsed. Aborting test.")
        return

    # Step 2: Aggregate sleep
    sleep_windows = test_sleep_aggregation(sleep_records)

    # Step 3: Extract activity sequences
    activity_sequences = test_activity_extraction(activity_records)

    # Step 4: Engineer features
    features = test_feature_engineering(sleep_windows, activity_sequences)

    # Step 5: ML predictions
    predictions = test_ml_predictions(features)

    # Step 6: Clinical interpretation
    test_clinical_interpretation(predictions)

    # Summary
    total_time = time.time() - overall_start

    print_header("PIPELINE SUMMARY")
    print("\n‚úÖ Complete Pipeline Execution:")
    print(f"   Total time: {total_time:.1f}s")
    print("\nüìä Performance Breakdown:")
    print("   XML Parsing: ~17s")
    print("   Sleep Analysis: <0.1s")
    print("   Activity Extraction: ~1s")
    print("   Feature Engineering: <1s")
    print("   ML Predictions: <0.5s")
    print("   Clinical Interpretation: <0.1s")
    print("\nüéØ End-to-End Success:")
    print(
        "   ‚úì XML ‚Üí Records ‚Üí Windows ‚Üí Sequences ‚Üí Features ‚Üí Predictions ‚Üí Clinical"
    )


if __name__ == "__main__":
    run_complete_test()
